{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cPickle as pickle\n",
    "import gzip\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (50000, 784) (50000,)\n",
      "Validation set (10000, 784) (10000,)\n",
      "Test set (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "with gzip.open('mnielsen/data/mnist.pkl.gz', 'rb') as f:\n",
    "    train_dataset, valid_dataset, test_dataset = pickle.load(f)\n",
    "\n",
    "print \"Training set\", train_dataset[0].shape, train_dataset[1].shape\n",
    "print \"Validation set\", valid_dataset[0].shape, valid_dataset[1].shape\n",
    "print \"Test set\", test_dataset[0].shape, test_dataset[1].shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Expanding impage number', 1000)\n",
      "('Expanding impage number', 2000)\n",
      "('Expanding impage number', 3000)\n",
      "('Expanding impage number', 4000)\n",
      "('Expanding impage number', 5000)\n",
      "('Expanding impage number', 6000)\n",
      "('Expanding impage number', 7000)\n",
      "('Expanding impage number', 8000)\n",
      "('Expanding impage number', 9000)\n",
      "('Expanding impage number', 10000)\n",
      "('Expanding impage number', 11000)\n",
      "('Expanding impage number', 12000)\n",
      "('Expanding impage number', 13000)\n",
      "('Expanding impage number', 14000)\n",
      "('Expanding impage number', 15000)\n",
      "('Expanding impage number', 16000)\n",
      "('Expanding impage number', 17000)\n",
      "('Expanding impage number', 18000)\n",
      "('Expanding impage number', 19000)\n",
      "('Expanding impage number', 20000)\n",
      "('Expanding impage number', 21000)\n",
      "('Expanding impage number', 22000)\n",
      "('Expanding impage number', 23000)\n",
      "('Expanding impage number', 24000)\n",
      "('Expanding impage number', 25000)\n",
      "('Expanding impage number', 26000)\n",
      "('Expanding impage number', 27000)\n",
      "('Expanding impage number', 28000)\n",
      "('Expanding impage number', 29000)\n",
      "('Expanding impage number', 30000)\n",
      "('Expanding impage number', 31000)\n",
      "('Expanding impage number', 32000)\n",
      "('Expanding impage number', 33000)\n",
      "('Expanding impage number', 34000)\n",
      "('Expanding impage number', 35000)\n",
      "('Expanding impage number', 36000)\n",
      "('Expanding impage number', 37000)\n",
      "('Expanding impage number', 38000)\n",
      "('Expanding impage number', 39000)\n",
      "('Expanding impage number', 40000)\n",
      "('Expanding impage number', 41000)\n",
      "('Expanding impage number', 42000)\n",
      "('Expanding impage number', 43000)\n",
      "('Expanding impage number', 44000)\n",
      "('Expanding impage number', 45000)\n",
      "('Expanding impage number', 46000)\n",
      "('Expanding impage number', 47000)\n",
      "('Expanding impage number', 48000)\n",
      "('Expanding impage number', 49000)\n",
      "('Expanding impage number', 50000)\n",
      "Saving expanded data. This may take a few minutes.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "expanded_pairs = []\n",
    "j = 0\n",
    "for x, y in zip(train_dataset[0], train_dataset[1]):\n",
    "    expanded_pairs.append((x,y))\n",
    "    image = np.reshape(x, (-1, 28))\n",
    "    j += 1\n",
    "    if j % 1000 == 0: print (\"Expanding impage number\", j)\n",
    "    for d, axis, index_position, index in [\n",
    "        (1, 0, \"first\", 0),\n",
    "        (-1, 0, \"first\", 27),\n",
    "        (1, 1, \"last\", 0),\n",
    "        (-1, 1, \"last\", 27)]:\n",
    "        new_img = np.roll(image, d, axis)\n",
    "        if index_position == 'first':\n",
    "            new_img[index, :] = np.zeros(28)\n",
    "        else:\n",
    "            new_img[:, index] = np.zeros(28)\n",
    "        expanded_pairs.append((np.reshape(new_img, 784), y))\n",
    "random.shuffle(expanded_pairs)\n",
    "expanded_training = [list(d) for d in zip(*expanded_pairs)]\n",
    "print \"Saving expanded data. This may take a few minutes.\"\n",
    "f = gzip.open(\"mnist_expanded.pkl.gz\", \"w\")\n",
    "pickle.dump((expanded_training, valid_dataset, test_dataset), f)\n",
    "f.close()\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (250000, 784) (250000,)\n",
      "Validation set (10000, 784) (10000,)\n",
      "Test set (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "with gzip.open('mnist_expanded1.pkl.gz', 'rb') as f:\n",
    "    train_dataset, valid_dataset, test_dataset = pickle.load(f)\n",
    "\n",
    "print \"Training set\", np.array(train_dataset[0]).shape, np.array(train_dataset[1]).shape\n",
    "print \"Validation set\", valid_dataset[0].shape, valid_dataset[1].shape\n",
    "print \"Test set\", test_dataset[0].shape, test_dataset[1].shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (250000, 28, 28, 1) (250000, 10)\n",
      "Validation set (10000, 28, 28, 1) (10000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def vectorized_result(j):\n",
    "    e = np.zeros(10)\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "train_data = np.array([np.reshape(x, (28,28,1)) for x in train_dataset[0]])\n",
    "train_labels = np.array([vectorized_result(y) for y in train_dataset[1]])\n",
    "valid_data = np.array([np.reshape(x, (28,28,1)) for x in valid_dataset[0]])\n",
    "valid_labels = np.array([vectorized_result(y) for y in valid_dataset[1]])\n",
    "test_data = np.array([np.reshape(x, (28,28,1)) for x in test_dataset[0]])\n",
    "test_labels = np.array([vectorized_result(y) for y in test_dataset[1]])\n",
    "print \"Training set\", train_data.shape, train_labels.shape\n",
    "print \"Validation set\", valid_data.shape, valid_labels.shape\n",
    "print \"Test set\", test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    # Input data\n",
    "    ### For convolutional layers\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "    ### For fully connected layers\n",
    "    # x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "    # y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "    \n",
    "    # Model\n",
    "    W = tf.Variable(tf.truncated_normal([5, 5, 1, 20], stddev=np.sqrt(1.0/(125))))\n",
    "    b = tf.Variable(tf.truncated_normal([20]))\n",
    "    a = tf.nn.conv2d(x, W, [1, 1, 1, 1], padding='VALID')\n",
    "    pool = tf.nn.max_pool(a, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
    "    z = tf.nn.relu(pool + b)\n",
    "    # For variable-sized batches tf.shape(x)[0]\n",
    "    # z = tf.reshape(a, [tf.shape(x)[0], (20*12*12)])\n",
    "    \n",
    "    W0 = tf.Variable(tf.truncated_normal([5, 5, 20, 40], stddev=np.sqrt(1.0/(250))))\n",
    "    b0 = tf.Variable(tf.truncated_normal([40]))\n",
    "    a = tf.nn.conv2d(z, W0, [1, 1, 1, 1], padding='VALID')\n",
    "    pool = tf.nn.max_pool(a, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
    "    a = tf.nn.relu(pool + b0)\n",
    "    # For variable-sized batches tf.shape(x)[0]\n",
    "    z = tf.reshape(a, [tf.shape(x)[0], (40*4*4)])\n",
    "    \n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([(40*4*4), 100], stddev=np.sqrt(1.0/(100))))\n",
    "    b1 = tf.Variable(tf.truncated_normal([100]))\n",
    "    a = tf.nn.relu(tf.matmul(z, W1) + b1)\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([100, 10], stddev=np.sqrt(1.0/10)))\n",
    "    b2 = tf.Variable(tf.truncated_normal([10]))\n",
    "    z = tf.matmul(a, W2) + b2\n",
    "    # 99.0% \n",
    "    \n",
    "    # Training\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(z, y))\n",
    "    \n",
    "    loss += 0.1 * (tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2))\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.03).minimize(loss)\n",
    "    \n",
    "    # Predictions\n",
    "    predictions = tf.nn.softmax(z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 35.163559\n",
      "Minibatch accuracy: 20.00%\n",
      "Validation accuracy: 9.67%\n",
      "Best Validation accuracy at step 0 and epoch 0\n",
      "Minibatch loss at step 1000: 1.546647\n",
      "Minibatch accuracy: 50.00%\n",
      "Validation accuracy: 81.05%\n",
      "Best Validation accuracy at step 1000 and epoch 0\n",
      "Minibatch loss at step 2000: 1.220054\n",
      "Minibatch accuracy: 70.00%\n",
      "Validation accuracy: 86.78%\n",
      "Best Validation accuracy at step 2000 and epoch 0\n",
      "Minibatch loss at step 3000: 0.311473\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.67%\n",
      "Best Validation accuracy at step 3000 and epoch 0\n",
      "Minibatch loss at step 4000: 0.345153\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 91.87%\n",
      "Duration: 19.05 sec\n",
      "Minibatch loss at step 0: 0.499727\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.33%\n",
      "Best Validation accuracy at step 0 and epoch 1\n",
      "Minibatch loss at step 1000: 0.702190\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 86.72%\n",
      "Minibatch loss at step 2000: 1.022972\n",
      "Minibatch accuracy: 60.00%\n",
      "Validation accuracy: 91.75%\n",
      "Minibatch loss at step 3000: 0.274301\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.57%\n",
      "Best Validation accuracy at step 3000 and epoch 1\n",
      "Minibatch loss at step 4000: 0.274935\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.18%\n",
      "Duration: 18.42 sec\n",
      "Minibatch loss at step 0: 0.366886\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.08%\n",
      "Minibatch loss at step 1000: 0.680047\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 89.04%\n",
      "Minibatch loss at step 2000: 0.773922\n",
      "Minibatch accuracy: 70.00%\n",
      "Validation accuracy: 93.12%\n",
      "Minibatch loss at step 3000: 0.287692\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.48%\n",
      "Minibatch loss at step 4000: 0.246070\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.94%\n",
      "Duration: 18.75 sec\n",
      "Minibatch loss at step 0: 0.386233\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.04%\n",
      "Minibatch loss at step 1000: 0.685971\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 89.42%\n",
      "Minibatch loss at step 2000: 0.872246\n",
      "Minibatch accuracy: 70.00%\n",
      "Validation accuracy: 93.26%\n",
      "Minibatch loss at step 3000: 0.263823\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.15%\n",
      "Minibatch loss at step 4000: 0.222450\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.22%\n",
      "Duration: 19.00 sec\n",
      "Minibatch loss at step 0: 0.334447\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.04%\n",
      "Minibatch loss at step 1000: 0.750261\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 88.83%\n",
      "Minibatch loss at step 2000: 0.885339\n",
      "Minibatch accuracy: 60.00%\n",
      "Validation accuracy: 94.71%\n",
      "Minibatch loss at step 3000: 0.227239\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.26%\n",
      "Minibatch loss at step 4000: 0.209889\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.41%\n",
      "Duration: 18.24 sec\n",
      "Minibatch loss at step 0: 0.264417\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.42%\n",
      "Minibatch loss at step 1000: 0.789944\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 90.96%\n",
      "Minibatch loss at step 2000: 0.869914\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 95.35%\n",
      "Minibatch loss at step 3000: 0.223947\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.36%\n",
      "Minibatch loss at step 4000: 0.219842\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.49%\n",
      "Duration: 18.50 sec\n",
      "Minibatch loss at step 0: 0.259469\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.68%\n",
      "Best Validation accuracy at step 0 and epoch 6\n",
      "Minibatch loss at step 1000: 0.721644\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 89.74%\n",
      "Minibatch loss at step 2000: 0.834929\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 95.59%\n",
      "Minibatch loss at step 3000: 0.255920\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.51%\n",
      "Minibatch loss at step 4000: 0.261016\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.69%\n",
      "Duration: 18.07 sec\n",
      "Minibatch loss at step 0: 0.264980\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.95%\n",
      "Best Validation accuracy at step 0 and epoch 7\n",
      "Minibatch loss at step 1000: 0.823029\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 91.03%\n",
      "Minibatch loss at step 2000: 0.672235\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 96.35%\n",
      "Minibatch loss at step 3000: 0.246620\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.55%\n",
      "Minibatch loss at step 4000: 0.223451\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.84%\n",
      "Duration: 18.12 sec\n",
      "Minibatch loss at step 0: 0.255493\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.83%\n",
      "Minibatch loss at step 1000: 0.765060\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 91.55%\n",
      "Minibatch loss at step 2000: 0.624661\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 96.57%\n",
      "Minibatch loss at step 3000: 0.259503\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.50%\n",
      "Minibatch loss at step 4000: 0.274625\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.29%\n",
      "Duration: 18.08 sec\n",
      "Minibatch loss at step 0: 0.257984\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.99%\n",
      "Best Validation accuracy at step 0 and epoch 9\n",
      "Minibatch loss at step 1000: 0.705131\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 90.60%\n",
      "Minibatch loss at step 2000: 0.571026\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 96.88%\n",
      "Minibatch loss at step 3000: 0.278863\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 94.17%\n",
      "Minibatch loss at step 4000: 0.307885\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.49%\n",
      "Duration: 18.07 sec\n",
      "Minibatch loss at step 0: 0.238939\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.32%\n",
      "Best Validation accuracy at step 0 and epoch 10\n",
      "Minibatch loss at step 1000: 0.711314\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 92.81%\n",
      "Minibatch loss at step 2000: 0.499180\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.81%\n",
      "Minibatch loss at step 3000: 0.217601\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.51%\n",
      "Minibatch loss at step 4000: 0.379423\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.71%\n",
      "Duration: 18.02 sec\n",
      "Minibatch loss at step 0: 0.288104\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.33%\n",
      "Best Validation accuracy at step 0 and epoch 11\n",
      "Minibatch loss at step 1000: 0.709226\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 92.33%\n",
      "Minibatch loss at step 2000: 0.583728\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.59%\n",
      "Minibatch loss at step 3000: 0.240358\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.38%\n",
      "Minibatch loss at step 4000: 0.439278\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.71%\n",
      "Duration: 18.09 sec\n",
      "Minibatch loss at step 0: 0.281939\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.38%\n",
      "Best Validation accuracy at step 0 and epoch 12\n",
      "Minibatch loss at step 1000: 0.645514\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 94.96%\n",
      "Minibatch loss at step 2000: 0.425204\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.11%\n",
      "Minibatch loss at step 3000: 0.219821\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.82%\n",
      "Minibatch loss at step 4000: 0.552028\n",
      "Minibatch accuracy: 80.00%\n",
      "Validation accuracy: 96.50%\n",
      "Duration: 17.95 sec\n",
      "Minibatch loss at step 0: 0.298458\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.52%\n",
      "Best Validation accuracy at step 0 and epoch 13\n",
      "Minibatch loss at step 1000: 0.658577\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.30%\n",
      "Minibatch loss at step 2000: 0.454544\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.31%\n",
      "Minibatch loss at step 3000: 0.193029\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.80%\n",
      "Minibatch loss at step 4000: 0.294841\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.67%\n",
      "Duration: 17.98 sec\n",
      "Minibatch loss at step 0: 0.281417\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.68%\n",
      "Best Validation accuracy at step 0 and epoch 14\n",
      "Minibatch loss at step 1000: 0.704526\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 94.90%\n",
      "Minibatch loss at step 2000: 0.442987\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.07%\n",
      "Minibatch loss at step 3000: 0.190128\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.07%\n",
      "Minibatch loss at step 4000: 0.336697\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.85%\n",
      "Duration: 17.95 sec\n",
      "Minibatch loss at step 0: 0.259087\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.61%\n",
      "Minibatch loss at step 1000: 0.661148\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.04%\n",
      "Minibatch loss at step 2000: 0.465730\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.14%\n",
      "Minibatch loss at step 3000: 0.189639\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.36%\n",
      "Minibatch loss at step 4000: 0.430169\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.78%\n",
      "Duration: 17.96 sec\n",
      "Minibatch loss at step 0: 0.295615\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.80%\n",
      "Best Validation accuracy at step 0 and epoch 16\n",
      "Minibatch loss at step 1000: 0.622069\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 94.36%\n",
      "Minibatch loss at step 2000: 0.448970\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.20%\n",
      "Minibatch loss at step 3000: 0.192605\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.25%\n",
      "Minibatch loss at step 4000: 0.355063\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.95%\n",
      "Duration: 17.98 sec\n",
      "Minibatch loss at step 0: 0.303564\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.81%\n",
      "Best Validation accuracy at step 0 and epoch 17\n",
      "Minibatch loss at step 1000: 0.668378\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 93.89%\n",
      "Minibatch loss at step 2000: 0.415049\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.15%\n",
      "Minibatch loss at step 3000: 0.193797\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.78%\n",
      "Minibatch loss at step 4000: 0.491381\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.82%\n",
      "Duration: 18.07 sec\n",
      "Minibatch loss at step 0: 0.308092\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.90%\n",
      "Best Validation accuracy at step 0 and epoch 18\n",
      "Minibatch loss at step 1000: 0.573685\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 91.29%\n",
      "Minibatch loss at step 2000: 0.347478\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.19%\n",
      "Minibatch loss at step 3000: 0.212800\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.82%\n",
      "Minibatch loss at step 4000: 0.579650\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.74%\n",
      "Duration: 17.96 sec\n",
      "Minibatch loss at step 0: 0.279585\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.92%\n",
      "Best Validation accuracy at step 0 and epoch 19\n",
      "Minibatch loss at step 1000: 0.625402\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 93.03%\n",
      "Minibatch loss at step 2000: 0.365881\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.89%\n",
      "Minibatch loss at step 3000: 0.197453\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.33%\n",
      "Minibatch loss at step 4000: 0.244049\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.72%\n",
      "Duration: 17.96 sec\n",
      "Minibatch loss at step 0: 0.263738\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.94%\n",
      "Best Validation accuracy at step 0 and epoch 20\n",
      "Minibatch loss at step 1000: 0.612266\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 91.65%\n",
      "Minibatch loss at step 2000: 0.318645\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.16%\n",
      "Minibatch loss at step 3000: 0.204821\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.13%\n",
      "Minibatch loss at step 4000: 0.252618\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.24%\n",
      "Duration: 18.06 sec\n",
      "Minibatch loss at step 0: 0.238401\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.83%\n",
      "Minibatch loss at step 1000: 0.624079\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 93.92%\n",
      "Minibatch loss at step 2000: 0.347544\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.98%\n",
      "Minibatch loss at step 3000: 0.183458\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.39%\n",
      "Minibatch loss at step 4000: 0.250672\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.12%\n",
      "Duration: 17.96 sec\n",
      "Minibatch loss at step 0: 0.245428\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.85%\n",
      "Minibatch loss at step 1000: 0.617260\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.70%\n",
      "Minibatch loss at step 2000: 0.296631\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.99%\n",
      "Minibatch loss at step 3000: 0.200537\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.87%\n",
      "Minibatch loss at step 4000: 0.315539\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.76%\n",
      "Duration: 17.99 sec\n",
      "Minibatch loss at step 0: 0.203274\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.71%\n",
      "Minibatch loss at step 1000: 0.642018\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.52%\n",
      "Minibatch loss at step 2000: 0.310641\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.12%\n",
      "Minibatch loss at step 3000: 0.201535\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 92.46%\n",
      "Minibatch loss at step 4000: 0.459560\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.29%\n",
      "Duration: 17.97 sec\n",
      "Minibatch loss at step 0: 0.236387\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.89%\n",
      "Minibatch loss at step 1000: 0.597256\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.33%\n",
      "Minibatch loss at step 2000: 0.282802\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.45%\n",
      "Minibatch loss at step 3000: 0.206976\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.73%\n",
      "Minibatch loss at step 4000: 0.341936\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.28%\n",
      "Duration: 17.97 sec\n",
      "Minibatch loss at step 0: 0.228046\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.76%\n",
      "Minibatch loss at step 1000: 0.533159\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 93.34%\n",
      "Minibatch loss at step 2000: 0.386877\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.11%\n",
      "Minibatch loss at step 3000: 0.189601\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.81%\n",
      "Minibatch loss at step 4000: 0.297277\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.10%\n",
      "Duration: 17.98 sec\n",
      "Minibatch loss at step 0: 0.228192\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.78%\n",
      "Minibatch loss at step 1000: 0.609714\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.56%\n",
      "Minibatch loss at step 2000: 0.279147\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.39%\n",
      "Minibatch loss at step 3000: 0.189365\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.94%\n",
      "Minibatch loss at step 4000: 0.308794\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.98%\n",
      "Duration: 17.95 sec\n",
      "Minibatch loss at step 0: 0.225968\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.76%\n",
      "Minibatch loss at step 1000: 0.493713\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 92.70%\n",
      "Minibatch loss at step 2000: 0.263684\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.34%\n",
      "Minibatch loss at step 3000: 0.167478\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.95%\n",
      "Minibatch loss at step 4000: 0.262444\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.25%\n",
      "Duration: 18.19 sec\n",
      "Minibatch loss at step 0: 0.222378\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.84%\n",
      "Minibatch loss at step 1000: 0.448663\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 92.85%\n",
      "Minibatch loss at step 2000: 0.235513\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.30%\n",
      "Minibatch loss at step 3000: 0.252760\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.53%\n",
      "Minibatch loss at step 4000: 0.317921\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.22%\n",
      "Duration: 18.18 sec\n",
      "Minibatch loss at step 0: 0.215586\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.77%\n",
      "Minibatch loss at step 1000: 0.459220\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 92.06%\n",
      "Minibatch loss at step 2000: 0.234817\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.30%\n",
      "Minibatch loss at step 3000: 0.184509\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 92.24%\n",
      "Minibatch loss at step 4000: 0.312136\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.09%\n",
      "Duration: 18.21 sec\n",
      "Minibatch loss at step 0: 0.238888\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.86%\n",
      "Minibatch loss at step 1000: 0.530032\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 92.26%\n",
      "Minibatch loss at step 2000: 0.253198\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.22%\n",
      "Minibatch loss at step 3000: 0.202607\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.42%\n",
      "Minibatch loss at step 4000: 0.221255\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.09%\n",
      "Duration: 18.21 sec\n",
      "Minibatch loss at step 0: 0.244982\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.92%\n",
      "Minibatch loss at step 1000: 0.418720\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 89.88%\n",
      "Minibatch loss at step 2000: 0.256754\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.61%\n",
      "Minibatch loss at step 3000: 0.208222\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 92.41%\n",
      "Minibatch loss at step 4000: 0.235343\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.65%\n",
      "Duration: 18.13 sec\n",
      "Minibatch loss at step 0: 0.268833\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.90%\n",
      "Minibatch loss at step 1000: 0.497198\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 89.80%\n",
      "Minibatch loss at step 2000: 0.249452\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.64%\n",
      "Minibatch loss at step 3000: 0.178861\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.14%\n",
      "Minibatch loss at step 4000: 0.239238\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.81%\n",
      "Duration: 18.05 sec\n",
      "Minibatch loss at step 0: 0.267210\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.89%\n",
      "Minibatch loss at step 1000: 0.433988\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 91.39%\n",
      "Minibatch loss at step 2000: 0.236687\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.52%\n",
      "Minibatch loss at step 3000: 0.190263\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.14%\n",
      "Minibatch loss at step 4000: 0.211602\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.47%\n",
      "Duration: 18.05 sec\n",
      "Minibatch loss at step 0: 0.273565\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.63%\n",
      "Minibatch loss at step 1000: 0.421673\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 89.67%\n",
      "Minibatch loss at step 2000: 0.247182\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.22%\n",
      "Minibatch loss at step 3000: 0.294340\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.84%\n",
      "Minibatch loss at step 4000: 0.322172\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.25%\n",
      "Duration: 17.96 sec\n",
      "Minibatch loss at step 0: 0.259358\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.69%\n",
      "Minibatch loss at step 1000: 0.434731\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 90.68%\n",
      "Minibatch loss at step 2000: 0.235486\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.44%\n",
      "Minibatch loss at step 3000: 0.249917\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 94.58%\n",
      "Minibatch loss at step 4000: 0.163879\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.29%\n",
      "Duration: 17.97 sec\n",
      "Minibatch loss at step 0: 0.249468\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 98.04%\n",
      "Best Validation accuracy at step 0 and epoch 36\n",
      "Minibatch loss at step 1000: 0.612587\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.64%\n",
      "Minibatch loss at step 2000: 0.233474\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.29%\n",
      "Minibatch loss at step 3000: 0.264878\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.90%\n",
      "Minibatch loss at step 4000: 0.268114\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.20%\n",
      "Duration: 17.94 sec\n",
      "Minibatch loss at step 0: 0.251819\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.86%\n",
      "Minibatch loss at step 1000: 0.526132\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 93.93%\n",
      "Minibatch loss at step 2000: 0.228543\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.08%\n",
      "Minibatch loss at step 3000: 0.178709\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.26%\n",
      "Minibatch loss at step 4000: 0.189255\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.81%\n",
      "Duration: 18.06 sec\n",
      "Minibatch loss at step 0: 0.276104\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.69%\n",
      "Minibatch loss at step 1000: 0.500579\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 89.85%\n",
      "Minibatch loss at step 2000: 0.219301\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.29%\n",
      "Minibatch loss at step 3000: 0.352496\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.48%\n",
      "Minibatch loss at step 4000: 0.175055\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.86%\n",
      "Duration: 18.10 sec\n",
      "Minibatch loss at step 0: 0.270372\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.98%\n",
      "Minibatch loss at step 1000: 0.544420\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 90.33%\n",
      "Minibatch loss at step 2000: 0.245973\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.31%\n",
      "Minibatch loss at step 3000: 0.209996\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.27%\n",
      "Minibatch loss at step 4000: 0.181407\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.01%\n",
      "Duration: 18.83 sec\n",
      "Minibatch loss at step 0: 0.255236\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.93%\n",
      "Minibatch loss at step 1000: 0.735462\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.53%\n",
      "Minibatch loss at step 2000: 0.208618\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.47%\n",
      "Minibatch loss at step 3000: 0.302235\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.91%\n",
      "Minibatch loss at step 4000: 0.200496\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.60%\n",
      "Duration: 18.58 sec\n",
      "Minibatch loss at step 0: 0.265463\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.64%\n",
      "Minibatch loss at step 1000: 0.535926\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 92.64%\n",
      "Minibatch loss at step 2000: 0.214755\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.25%\n",
      "Minibatch loss at step 3000: 0.178713\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.26%\n",
      "Minibatch loss at step 4000: 0.180499\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.60%\n",
      "Duration: 19.19 sec\n",
      "Minibatch loss at step 0: 0.247843\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.94%\n",
      "Minibatch loss at step 1000: 0.682134\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 93.81%\n",
      "Minibatch loss at step 2000: 0.232284\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.55%\n",
      "Minibatch loss at step 3000: 0.241596\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 94.65%\n",
      "Minibatch loss at step 4000: 0.178227\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.68%\n",
      "Duration: 17.98 sec\n",
      "Minibatch loss at step 0: 0.277246\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.87%\n",
      "Minibatch loss at step 1000: 0.566425\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 94.82%\n",
      "Minibatch loss at step 2000: 0.210834\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.39%\n",
      "Minibatch loss at step 3000: 0.278535\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.07%\n",
      "Minibatch loss at step 4000: 0.177693\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.78%\n",
      "Duration: 17.97 sec\n",
      "Minibatch loss at step 0: 0.249414\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.91%\n",
      "Minibatch loss at step 1000: 0.749731\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.99%\n",
      "Minibatch loss at step 2000: 0.217611\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.32%\n",
      "Minibatch loss at step 3000: 0.263608\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.21%\n",
      "Minibatch loss at step 4000: 0.205661\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.94%\n",
      "Duration: 17.94 sec\n",
      "Minibatch loss at step 0: 0.275589\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 98.07%\n",
      "Best Validation accuracy at step 0 and epoch 45\n",
      "Minibatch loss at step 1000: 0.598206\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.60%\n",
      "Minibatch loss at step 2000: 0.218254\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.18%\n",
      "Minibatch loss at step 3000: 0.166580\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.66%\n",
      "Minibatch loss at step 4000: 0.165065\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.18%\n",
      "Duration: 17.96 sec\n",
      "Minibatch loss at step 0: 0.273259\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.85%\n",
      "Minibatch loss at step 1000: 0.771919\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.91%\n",
      "Minibatch loss at step 2000: 0.237458\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.51%\n",
      "Minibatch loss at step 3000: 0.175340\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.59%\n",
      "Minibatch loss at step 4000: 0.164973\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.54%\n",
      "Duration: 17.95 sec\n",
      "Minibatch loss at step 0: 0.408001\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 98.04%\n",
      "Minibatch loss at step 1000: 0.631878\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.17%\n",
      "Minibatch loss at step 2000: 0.230090\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.69%\n",
      "Minibatch loss at step 3000: 0.172347\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.67%\n",
      "Minibatch loss at step 4000: 0.186652\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.57%\n",
      "Duration: 17.97 sec\n",
      "Minibatch loss at step 0: 0.298104\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.99%\n",
      "Minibatch loss at step 1000: 0.677076\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 94.25%\n",
      "Minibatch loss at step 2000: 0.221516\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.39%\n",
      "Minibatch loss at step 3000: 0.162027\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.20%\n",
      "Minibatch loss at step 4000: 0.171723\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.51%\n",
      "Duration: 17.91 sec\n",
      "Minibatch loss at step 0: 0.227956\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 98.01%\n",
      "Minibatch loss at step 1000: 0.657561\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 94.57%\n",
      "Minibatch loss at step 2000: 0.220438\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.86%\n",
      "Minibatch loss at step 3000: 0.397029\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.54%\n",
      "Minibatch loss at step 4000: 0.168995\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.55%\n",
      "Duration: 17.93 sec\n",
      "Minibatch loss at step 0: 0.223198\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.82%\n",
      "Minibatch loss at step 1000: 0.627892\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 93.62%\n",
      "Minibatch loss at step 2000: 0.219263\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.37%\n",
      "Minibatch loss at step 3000: 0.210248\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 93.23%\n",
      "Minibatch loss at step 4000: 0.170593\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.71%\n",
      "Duration: 18.01 sec\n",
      "Minibatch loss at step 0: 0.248247\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 98.00%\n",
      "Minibatch loss at step 1000: 0.753920\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 94.95%\n",
      "Minibatch loss at step 2000: 0.241318\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.60%\n",
      "Minibatch loss at step 3000: 0.195604\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.24%\n",
      "Minibatch loss at step 4000: 0.180204\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.35%\n",
      "Duration: 17.95 sec\n",
      "Minibatch loss at step 0: 0.236141\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.83%\n",
      "Minibatch loss at step 1000: 0.512991\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 93.22%\n",
      "Minibatch loss at step 2000: 0.390624\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.81%\n",
      "Minibatch loss at step 3000: 0.175416\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.29%\n",
      "Minibatch loss at step 4000: 0.163409\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.92%\n",
      "Duration: 17.94 sec\n",
      "Minibatch loss at step 0: 0.236818\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.89%\n",
      "Minibatch loss at step 1000: 0.730239\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.00%\n",
      "Minibatch loss at step 2000: 0.224736\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.37%\n",
      "Minibatch loss at step 3000: 0.225451\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.22%\n",
      "Minibatch loss at step 4000: 0.172317\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.32%\n",
      "Duration: 18.01 sec\n",
      "Minibatch loss at step 0: 0.221003\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 98.10%\n",
      "Best Validation accuracy at step 0 and epoch 54\n",
      "Minibatch loss at step 1000: 0.806302\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.19%\n",
      "Minibatch loss at step 2000: 0.212450\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.88%\n",
      "Minibatch loss at step 3000: 0.172325\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.18%\n",
      "Minibatch loss at step 4000: 0.158115\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.32%\n",
      "Duration: 17.94 sec\n",
      "Minibatch loss at step 0: 0.225974\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 98.10%\n",
      "Best Validation accuracy at step 0 and epoch 55\n",
      "Minibatch loss at step 1000: 0.470286\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 93.10%\n",
      "Minibatch loss at step 2000: 0.210323\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.77%\n",
      "Minibatch loss at step 3000: 0.518730\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 95.81%\n",
      "Minibatch loss at step 4000: 0.172725\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.67%\n",
      "Duration: 17.93 sec\n",
      "Minibatch loss at step 0: 0.220256\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 98.10%\n",
      "Best Validation accuracy at step 0 and epoch 56\n",
      "Minibatch loss at step 1000: 0.638775\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 94.97%\n",
      "Minibatch loss at step 2000: 0.270128\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.77%\n",
      "Minibatch loss at step 3000: 0.159599\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.44%\n",
      "Minibatch loss at step 4000: 0.199153\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.16%\n",
      "Duration: 17.98 sec\n",
      "Minibatch loss at step 0: 0.224949\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.93%\n",
      "Minibatch loss at step 1000: 0.606334\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.30%\n",
      "Minibatch loss at step 2000: 0.336516\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 97.79%\n",
      "Minibatch loss at step 3000: 0.172210\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.27%\n",
      "Minibatch loss at step 4000: 0.187460\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.03%\n",
      "Duration: 17.99 sec\n",
      "Minibatch loss at step 0: 0.327901\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 98.01%\n",
      "Minibatch loss at step 1000: 0.812132\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.18%\n",
      "Minibatch loss at step 2000: 0.215622\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 98.09%\n",
      "Minibatch loss at step 3000: 0.181129\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 96.75%\n",
      "Minibatch loss at step 4000: 0.156018\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.69%\n",
      "Duration: 17.95 sec\n",
      "Minibatch loss at step 0: 0.222094\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.88%\n",
      "Minibatch loss at step 1000: 0.688860\n",
      "Minibatch accuracy: 90.00%\n",
      "Validation accuracy: 96.76%\n",
      "Minibatch loss at step 2000: 0.201824\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 98.16%\n",
      "Best Validation accuracy at step 2000 and epoch 59\n",
      "Minibatch loss at step 3000: 0.188182\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 95.91%\n",
      "Minibatch loss at step 4000: 0.177452\n",
      "Minibatch accuracy: 100.00%\n",
      "Validation accuracy: 97.05%\n",
      "Duration: 17.91 sec\n",
      "Test accuracy: 98.06%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 60\n",
    "num_steps = 50000/batch_size\n",
    "\n",
    "'''\n",
    "for each epoch\n",
    "   randomly shuffle training data\n",
    "   for each N size batch of training data\n",
    "      train model\n",
    "   view train cost\n",
    "   compute train accuracy\n",
    "   view valid cost\n",
    "   compute valid accuracy\n",
    "compute test accuracy\n",
    "'''\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print \"Initialized\"\n",
    "    best_validation_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            batch_data = train_data[offset:(offset + batch_size), :, :, :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Feed dictionary\n",
    "            feed_dict = {x: batch_data, y: batch_labels}\n",
    "            _, C, pred = session.run([optimizer,loss,predictions],feed_dict=feed_dict)\n",
    "            if (step % 1000 == 0):\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, C))\n",
    "                print(\"Minibatch accuracy: %.2f%%\" % accuracy(pred, batch_labels))\n",
    "                feed_dict = {x: valid_data}\n",
    "                pred = session.run(predictions, feed_dict=feed_dict)\n",
    "                valid_acc = accuracy(np.array(pred), valid_labels)\n",
    "                print(\"Validation accuracy: %.2f%%\" % valid_acc)\n",
    "                if (valid_acc >= best_validation_acc):\n",
    "                    best_validation_acc = valid_acc\n",
    "                    print \"Best Validation accuracy at step\", step, \"and epoch\", epoch\n",
    "        print (\"Duration: %.2f sec\" % (time.time() - start_time))\n",
    "    feed_dict = {x: test_data}\n",
    "    pred = session.run(predictions, feed_dict=feed_dict)\n",
    "    print (\"Test accuracy: %.2f%%\" % accuracy(np.array(pred), test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
