{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cPickle as pickle\n",
    "import gzip\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (50000, 784) (50000,)\n",
      "Validation set (10000, 784) (10000,)\n",
      "Test set (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "with gzip.open(\"mnist.pkl.gz\", 'rb') as f:\n",
    "    train_dataset, valid_dataset, test_dataset = pickle.load(f)\n",
    "'''\n",
    "train_data = train_dataset[0]\n",
    "train_labels = train_dataset[1]\n",
    "valid_data = valid_dataset[0]\n",
    "valid_labels = valid_dataset[1]\n",
    "test_data = test_dataset[0]\n",
    "test_labels = test_dataset[1]\n",
    "'''\n",
    "print \"Training set\", train_dataset[0].shape, train_dataset[1].shape\n",
    "print \"Validation set\", valid_dataset[0].shape, valid_dataset[1].shape\n",
    "print \"Test set\", test_dataset[0].shape, test_dataset[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (50000, 784, 1) (50000, 10, 1)\n",
      "Validation set (10000, 784, 1) (10000, 10, 1)\n",
      "Test set (10000, 784, 1) (10000, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "def vectorized_result(j):\n",
    "    e = np.zeros((10))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "train_data = np.array([np.reshape(x, (784,1)) for x in train_dataset[0]])\n",
    "train_labels = np.array([vectorized_result(y) for y in train_dataset[1]])\n",
    "valid_data = np.array([np.reshape(x, (784,1)) for x in valid_dataset[0]])\n",
    "valid_labels = np.array([vectorized_result(y) for y in valid_dataset[1]])\n",
    "test_data = np.array([np.reshape(x, (784,1)) for x in test_dataset[0]])\n",
    "test_labels = np.array([vectorized_result(y) for y in test_dataset[1]])\n",
    "print \"Training set\", train_data.shape, train_labels.shape\n",
    "print \"Validation set\", valid_data.shape, valid_labels.shape\n",
    "print \"Test set\", test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (50000, 28, 28, 1) (50000, 10)\n",
      "Validation set (10000, 28, 28, 1) (10000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def vectorized_result(j):\n",
    "    e = np.zeros((10))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "train_data = np.array([np.reshape(x, (28,28,1)) for x in train_dataset[0]])\n",
    "train_labels = np.array([vectorized_result(y) for y in train_dataset[1]])\n",
    "valid_data = np.array([np.reshape(x, (28,28,1)) for x in valid_dataset[0]])\n",
    "valid_labels = np.array([vectorized_result(y) for y in valid_dataset[1]])\n",
    "test_data = np.array([np.reshape(x, (28,28,1)) for x in test_dataset[0]])\n",
    "test_labels = np.array([vectorized_result(y) for y in test_dataset[1]])\n",
    "print \"Training set\", train_data.shape, train_labels.shape\n",
    "print \"Validation set\", valid_data.shape, valid_labels.shape\n",
    "print \"Test set\", test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (50000, 784) (50000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def vectorized_result(j):\n",
    "    e = np.zeros((10))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "train_data = np.array([np.reshape(x, (784)) for x in train_dataset[0]])\n",
    "train_labels = np.array([vectorized_result(y) for y in train_dataset[1]])\n",
    "valid_data = np.array([np.reshape(x, (784)) for x in valid_dataset[0]])\n",
    "valid_labels = np.array([vectorized_result(y) for y in valid_dataset[1]])\n",
    "test_data = np.array([np.reshape(x, (784)) for x in test_dataset[0]])\n",
    "test_labels = np.array([vectorized_result(y) for y in test_dataset[1]])\n",
    "print \"Training set\", train_data.shape, train_labels.shape\n",
    "print \"Validation set\", valid_data.shape, valid_labels.shape\n",
    "print \"Test set\", test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    # Input data\n",
    "    ### For convolutional layers\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "    ### For fully connected layers\n",
    "    # x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "    # y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "    \n",
    "    # Model\n",
    "    W = tf.Variable(tf.truncated_normal([5, 5, 1, 20], stddev=np.sqrt(1.0/(576))))\n",
    "    b = tf.Variable(tf.truncated_normal([20]))\n",
    "    a = tf.nn.conv2d(x, W, [1, 1, 1, 1], padding='VALID')\n",
    "    pool = tf.nn.max_pool(a, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
    "    z = tf.nn.relu(pool + b)\n",
    "    # For variable-sized batches tf.shape(x)[0]\n",
    "    # z = tf.reshape(a, [tf.shape(x)[0], (20*12*12)])\n",
    "    \n",
    "    W0 = tf.Variable(tf.truncated_normal([5, 5, 20, 40], stddev=np.sqrt(1.0/(125))))\n",
    "    b0 = tf.Variable(tf.truncated_normal([40]))\n",
    "    a = tf.nn.conv2d(z, W0, [1, 1, 1, 1], padding='VALID')\n",
    "    pool = tf.nn.max_pool(a, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
    "    a = tf.nn.relu(pool + b0)\n",
    "    # For variable-sized batches tf.shape(x)[0]\n",
    "    z = tf.reshape(a, [tf.shape(x)[0], (40*4*4)])\n",
    "    \n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([(40*4*4), 100], stddev=np.sqrt(1.0/(100))))\n",
    "    b1 = tf.Variable(tf.truncated_normal([100]))\n",
    "    a = tf.nn.relu(tf.matmul(z, W1) + b1)\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([100, 10], stddev=np.sqrt(1.0/10)))\n",
    "    b2 = tf.Variable(tf.truncated_normal([10]))\n",
    "    z = tf.matmul(a, W2) + b2\n",
    "    # 98.86 - 99.0% \n",
    "    '''\n",
    "    W = tf.Variable(tf.truncated_normal([5, 5, 1, 20], stddev=np.sqrt(1.0/(576))))\n",
    "    b = tf.Variable(tf.truncated_normal([20]))\n",
    "    a = tf.nn.conv2d(x, W, [1, 1, 1, 1], padding='VALID')\n",
    "    pool = tf.nn.max_pool(a, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
    "    a = tf.nn.relu(pool + b)\n",
    "    # For variable-sized batches tf.shape(x)[0]\n",
    "    z = tf.reshape(a, [tf.shape(x)[0], (20*12*12)])\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([(20*12*12), 100], stddev=np.sqrt(1.0/(100))))\n",
    "    b1 = tf.Variable(tf.truncated_normal([100]))\n",
    "    a = tf.nn.sigmoid(tf.matmul(z, W1) + b1)\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([100, 10], stddev=np.sqrt(1.0/10)))\n",
    "    b2 = tf.Variable(tf.truncated_normal([10]))\n",
    "    z = tf.matmul(a, W2) + b2\n",
    "    # 98.6%\n",
    "    '''\n",
    "    '''\n",
    "    W1 = tf.Variable(tf.truncated_normal([784, 100], stddev=np.sqrt(1.0/(100))))\n",
    "    b = tf.Variable(tf.truncated_normal([100]))\n",
    "    a = tf.nn.sigmoid(tf.matmul(x, W1) + b)\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([100, 10], stddev=np.sqrt(1.0/10)))\n",
    "    b2 = tf.Variable(tf.truncated_normal([10]))\n",
    "    z = tf.matmul(a, W2) + b2\n",
    "    # 97.6%\n",
    "    '''\n",
    "    '''\n",
    "    W1 = tf.Variable(tf.truncated_normal([784, 10], stddev=np.sqrt(1.0/(10))))\n",
    "    b = tf.Variable(tf.truncated_normal([10]))\n",
    "    \n",
    "    z = tf.matmul(x, W1) + b\n",
    "    '''\n",
    "    # Training\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(z, y))\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "    \n",
    "    # Predictions\n",
    "    predictions = tf.nn.softmax(z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.675883\n",
      "Minibatch accuracy: 10.0%\n",
      "Validation accuracy: 9.8%\n",
      "Best Validation accuracy at step 0 and epoch 0\n",
      "Minibatch loss at step 1000: 2.203971\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 12.1%\n",
      "Best Validation accuracy at step 1000 and epoch 0\n",
      "Minibatch loss at step 2000: 0.360574\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 83.7%\n",
      "Best Validation accuracy at step 2000 and epoch 0\n",
      "Minibatch loss at step 3000: 0.052116\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.1%\n",
      "Best Validation accuracy at step 3000 and epoch 0\n",
      "Minibatch loss at step 4000: 0.162207\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.5%\n",
      "Duration: 124.69%\n",
      "Minibatch loss at step 0: 0.043680\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.9%\n",
      "Best Validation accuracy at step 0 and epoch 1\n",
      "Minibatch loss at step 1000: 0.048975\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.9%\n",
      "Best Validation accuracy at step 1000 and epoch 1\n",
      "Minibatch loss at step 2000: 0.125873\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 95.7%\n",
      "Best Validation accuracy at step 2000 and epoch 1\n",
      "Minibatch loss at step 3000: 0.092552\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 95.8%\n",
      "Best Validation accuracy at step 3000 and epoch 1\n",
      "Minibatch loss at step 4000: 0.027982\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 96.2%\n",
      "Best Validation accuracy at step 4000 and epoch 1\n",
      "Duration: 135.37%\n",
      "Minibatch loss at step 0: 0.014444\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 95.5%\n",
      "Minibatch loss at step 1000: 0.016265\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 96.4%\n",
      "Best Validation accuracy at step 1000 and epoch 2\n",
      "Minibatch loss at step 2000: 0.022626\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 96.8%\n",
      "Best Validation accuracy at step 2000 and epoch 2\n",
      "Minibatch loss at step 3000: 0.059376\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 96.5%\n",
      "Minibatch loss at step 4000: 0.004191\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 96.8%\n",
      "Best Validation accuracy at step 4000 and epoch 2\n",
      "Duration: 134.57%\n",
      "Minibatch loss at step 0: 0.011102\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 96.8%\n",
      "Minibatch loss at step 1000: 0.010819\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 96.8%\n",
      "Best Validation accuracy at step 1000 and epoch 3\n",
      "Minibatch loss at step 2000: 0.009785\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.3%\n",
      "Best Validation accuracy at step 2000 and epoch 3\n",
      "Minibatch loss at step 3000: 0.152725\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 97.2%\n",
      "Minibatch loss at step 4000: 0.017603\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.5%\n",
      "Best Validation accuracy at step 4000 and epoch 3\n",
      "Duration: 120.06%\n",
      "Minibatch loss at step 0: 0.008721\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 1000: 0.009625\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.7%\n",
      "Best Validation accuracy at step 1000 and epoch 4\n",
      "Minibatch loss at step 2000: 0.015892\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 3000: 0.171404\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 97.7%\n",
      "Best Validation accuracy at step 3000 and epoch 4\n",
      "Minibatch loss at step 4000: 0.012285\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.7%\n",
      "Duration: 118.58%\n",
      "Minibatch loss at step 0: 0.005291\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.0%\n",
      "Best Validation accuracy at step 0 and epoch 5\n",
      "Minibatch loss at step 1000: 0.002425\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.8%\n",
      "Minibatch loss at step 2000: 0.007429\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.9%\n",
      "Minibatch loss at step 3000: 0.181832\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 98.0%\n",
      "Minibatch loss at step 4000: 0.004894\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.0%\n",
      "Best Validation accuracy at step 4000 and epoch 5\n",
      "Duration: 118.09%\n",
      "Minibatch loss at step 0: 0.006849\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.0%\n",
      "Best Validation accuracy at step 0 and epoch 6\n",
      "Minibatch loss at step 1000: 0.001785\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.8%\n",
      "Minibatch loss at step 2000: 0.007464\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.1%\n",
      "Best Validation accuracy at step 2000 and epoch 6\n",
      "Minibatch loss at step 3000: 0.114710\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 98.1%\n",
      "Minibatch loss at step 4000: 0.006734\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.0%\n",
      "Duration: 119.05%\n",
      "Minibatch loss at step 0: 0.002461\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.9%\n",
      "Minibatch loss at step 1000: 0.004642\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.0%\n",
      "Minibatch loss at step 2000: 0.005406\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.2%\n",
      "Best Validation accuracy at step 2000 and epoch 7\n",
      "Minibatch loss at step 3000: 0.023379\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.2%\n",
      "Best Validation accuracy at step 3000 and epoch 7\n",
      "Minibatch loss at step 4000: 0.002752\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.2%\n",
      "Best Validation accuracy at step 4000 and epoch 7\n",
      "Duration: 119.78%\n",
      "Minibatch loss at step 0: 0.003058\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.2%\n",
      "Best Validation accuracy at step 0 and epoch 8\n",
      "Minibatch loss at step 1000: 0.003017\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.0%\n",
      "Minibatch loss at step 2000: 0.001029\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.2%\n",
      "Minibatch loss at step 3000: 0.016270\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Best Validation accuracy at step 3000 and epoch 8\n",
      "Minibatch loss at step 4000: 0.010232\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Duration: 121.02%\n",
      "Minibatch loss at step 0: 0.002792\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.2%\n",
      "Minibatch loss at step 1000: 0.001512\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 2000: 0.001483\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.2%\n",
      "Minibatch loss at step 3000: 0.029142\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 4000: 0.034007\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Duration: 120.78%\n",
      "Minibatch loss at step 0: 0.003988\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.1%\n",
      "Minibatch loss at step 1000: 0.000705\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 2000: 0.002096\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 3000: 0.057277\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 4000: 0.001498\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Duration: 119.10%\n",
      "Minibatch loss at step 0: 0.003330\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.1%\n",
      "Minibatch loss at step 1000: 0.004402\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 2000: 0.001427\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 3000: 0.004656\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 4000: 0.000252\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Duration: 119.73%\n",
      "Minibatch loss at step 0: 0.002083\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 1000: 0.000555\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 2000: 0.002526\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 3000: 0.001306\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 4000: 0.004489\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Duration: 121.83%\n",
      "Minibatch loss at step 0: 0.001659\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 1000: 0.000236\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 2000: 0.012301\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Best Validation accuracy at step 2000 and epoch 13\n",
      "Minibatch loss at step 3000: 0.011350\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Best Validation accuracy at step 3000 and epoch 13\n",
      "Minibatch loss at step 4000: 0.004081\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Duration: 121.82%\n",
      "Minibatch loss at step 0: 0.001421\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Best Validation accuracy at step 0 and epoch 14\n",
      "Minibatch loss at step 1000: 0.004575\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 2000: 0.000297\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 3000: 0.002000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 4000: 0.001454\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Duration: 121.18%\n",
      "Minibatch loss at step 0: 0.001991\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 1000: 0.000908\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 2000: 0.000640\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Best Validation accuracy at step 2000 and epoch 15\n",
      "Minibatch loss at step 3000: 0.005161\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 4000: 0.000098\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Duration: 119.63%\n",
      "Minibatch loss at step 0: 0.003298\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 1000: 0.001819\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 2000: 0.000495\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 3000: 0.001845\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 4000: 0.000091\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Duration: 120.44%\n",
      "Minibatch loss at step 0: 0.002698\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 1000: 0.000313\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Best Validation accuracy at step 1000 and epoch 17\n",
      "Minibatch loss at step 2000: 0.001498\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 3000: 0.005940\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 4000: 0.002239\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Best Validation accuracy at step 4000 and epoch 17\n",
      "Duration: 120.16%\n",
      "Minibatch loss at step 0: 0.001874\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 1000: 0.000698\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 2000: 0.004529\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 3000: 0.001584\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 4000: 0.004676\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Duration: 120.01%\n",
      "Minibatch loss at step 0: 0.005091\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 1000: 0.000390\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 2000: 0.002527\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 3000: 0.001381\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Best Validation accuracy at step 3000 and epoch 19\n",
      "Minibatch loss at step 4000: 0.000674\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Duration: 121.93%\n",
      "Minibatch loss at step 0: 0.006706\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 1000: 0.004655\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 2000: 0.008948\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 3000: 0.000430\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 4000: 0.001341\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Duration: 118.99%\n",
      "Minibatch loss at step 0: 0.005095\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 1000: 0.000608\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 2000: 0.001134\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 3000: 0.019440\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Best Validation accuracy at step 3000 and epoch 21\n",
      "Minibatch loss at step 4000: 0.002379\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Duration: 121.21%\n",
      "Minibatch loss at step 0: 0.002256\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 1000: 0.000209\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 2000: 0.002838\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 3000: 0.001983\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 4000: 0.004288\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Duration: 122.56%\n",
      "Minibatch loss at step 0: 0.004732\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 1000: 0.002979\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 2000: 0.001047\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Best Validation accuracy at step 2000 and epoch 23\n",
      "Minibatch loss at step 3000: 0.004778\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 4000: 0.000674\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Duration: 121.39%\n",
      "Minibatch loss at step 0: 0.003529\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 1000: 0.000235\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 2000: 0.004609\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Best Validation accuracy at step 2000 and epoch 24\n",
      "Minibatch loss at step 3000: 0.019881\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 4000: 0.000260\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Duration: 120.87%\n",
      "Minibatch loss at step 0: 0.003801\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 1000: 0.000049\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 2000: 0.000297\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 3000: 0.002938\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 4000: 0.000170\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Duration: 120.05%\n",
      "Minibatch loss at step 0: 0.000432\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 1000: 0.000840\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 2000: 0.002998\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 3000: 0.064160\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 4000: 0.000084\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Duration: 121.09%\n",
      "Minibatch loss at step 0: 0.003842\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 1000: 0.000160\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 2000: 0.000140\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 3000: 0.003438\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 4000: 0.000093\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Duration: 119.31%\n",
      "Minibatch loss at step 0: 0.000178\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 1000: 0.000121\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 2000: 0.000339\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000829\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Best Validation accuracy at step 3000 and epoch 28\n",
      "Minibatch loss at step 4000: 0.000096\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 119.11%\n",
      "Minibatch loss at step 0: 0.000305\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 1000: 0.000192\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 2000: 0.000904\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 3000: 0.000354\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 4000: 0.000094\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 120.82%\n",
      "Minibatch loss at step 0: 0.000270\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 1000: 0.000122\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.001228\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 3000: 0.000310\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 4000: 0.000094\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Duration: 119.35%\n",
      "Minibatch loss at step 0: 0.000386\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000155\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 2000: 0.000253\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 3000: 0.000399\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 4000: 0.000119\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Duration: 117.84%\n",
      "Minibatch loss at step 0: 0.000356\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000130\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 2000: 0.000196\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000356\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 4000: 0.000157\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Duration: 119.18%\n",
      "Minibatch loss at step 0: 0.000331\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 1000: 0.000147\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 2000: 0.000144\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000347\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000197\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 118.73%\n",
      "Minibatch loss at step 0: 0.000290\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000192\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 2000: 0.000118\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000352\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000225\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 118.54%\n",
      "Minibatch loss at step 0: 0.000266\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000197\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000103\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000364\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000230\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 119.08%\n",
      "Minibatch loss at step 0: 0.000248\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000216\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000091\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000390\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000232\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 118.39%\n",
      "Minibatch loss at step 0: 0.000224\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 1000: 0.000237\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000080\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000391\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000230\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 114.01%\n",
      "Minibatch loss at step 0: 0.000203\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000258\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000072\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000388\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000227\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 116.06%\n",
      "Minibatch loss at step 0: 0.000187\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000281\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000066\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000378\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000223\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 115.62%\n",
      "Minibatch loss at step 0: 0.000169\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000296\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000060\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Best Validation accuracy at step 2000 and epoch 40\n",
      "Minibatch loss at step 3000: 0.000360\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000226\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 115.40%\n",
      "Minibatch loss at step 0: 0.000158\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000307\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Best Validation accuracy at step 1000 and epoch 41\n",
      "Minibatch loss at step 2000: 0.000056\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Best Validation accuracy at step 2000 and epoch 41\n",
      "Minibatch loss at step 3000: 0.000346\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000223\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 118.31%\n",
      "Minibatch loss at step 0: 0.000147\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000319\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Best Validation accuracy at step 1000 and epoch 42\n",
      "Minibatch loss at step 2000: 0.000054\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Best Validation accuracy at step 2000 and epoch 42\n",
      "Minibatch loss at step 3000: 0.000335\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000221\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 120.49%\n",
      "Minibatch loss at step 0: 0.000137\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000335\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000052\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Best Validation accuracy at step 2000 and epoch 43\n",
      "Minibatch loss at step 3000: 0.000322\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000217\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 118.81%\n",
      "Minibatch loss at step 0: 0.000127\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000345\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000051\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 2000 and epoch 44\n",
      "Minibatch loss at step 3000: 0.000309\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000213\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 119.62%\n",
      "Minibatch loss at step 0: 0.000119\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000352\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000049\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 2000 and epoch 45\n",
      "Minibatch loss at step 3000: 0.000290\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000207\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 119.76%\n",
      "Minibatch loss at step 0: 0.000112\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000359\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000048\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 2000 and epoch 46\n",
      "Minibatch loss at step 3000: 0.000273\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000201\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 118.77%\n",
      "Minibatch loss at step 0: 0.000106\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000367\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000047\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000256\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000196\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Duration: 120.50%\n",
      "Minibatch loss at step 0: 0.000100\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000374\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000045\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000243\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000191\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 4000 and epoch 48\n",
      "Duration: 119.49%\n",
      "Minibatch loss at step 0: 0.000095\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000382\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000045\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 3000: 0.000231\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000185\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 4000 and epoch 49\n",
      "Duration: 120.70%\n",
      "Minibatch loss at step 0: 0.000091\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 1000: 0.000387\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 2000: 0.000044\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 3000: 0.000218\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000180\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 4000 and epoch 50\n",
      "Duration: 118.37%\n",
      "Minibatch loss at step 0: 0.000087\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 1000: 0.000394\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 2000: 0.000043\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 3000: 0.000205\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000175\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 4000 and epoch 51\n",
      "Duration: 117.19%\n",
      "Minibatch loss at step 0: 0.000084\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 1000: 0.000402\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 2000: 0.000043\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 3000: 0.000197\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000171\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 4000 and epoch 52\n",
      "Duration: 121.99%\n",
      "Minibatch loss at step 0: 0.000080\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 1000: 0.000410\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 1000 and epoch 53\n",
      "Minibatch loss at step 2000: 0.000042\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 3000: 0.000188\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000168\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 4000 and epoch 53\n",
      "Duration: 120.41%\n",
      "Minibatch loss at step 0: 0.000077\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 1000: 0.000416\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 1000 and epoch 54\n",
      "Minibatch loss at step 2000: 0.000042\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 2000 and epoch 54\n",
      "Minibatch loss at step 3000: 0.000181\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000164\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 4000 and epoch 54\n",
      "Duration: 120.77%\n",
      "Minibatch loss at step 0: 0.000074\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 0 and epoch 55\n",
      "Minibatch loss at step 1000: 0.000419\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 1000 and epoch 55\n",
      "Minibatch loss at step 2000: 0.000042\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 2000 and epoch 55\n",
      "Minibatch loss at step 3000: 0.000174\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000162\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 4000 and epoch 55\n",
      "Duration: 120.10%\n",
      "Minibatch loss at step 0: 0.000072\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 1000: 0.000418\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 1000 and epoch 56\n",
      "Minibatch loss at step 2000: 0.000041\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 2000 and epoch 56\n",
      "Minibatch loss at step 3000: 0.000167\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000159\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Best Validation accuracy at step 4000 and epoch 56\n",
      "Duration: 120.70%\n",
      "Minibatch loss at step 0: 0.000069\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 1000: 0.000411\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 2000: 0.000041\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 3000: 0.000159\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000157\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Duration: 120.18%\n",
      "Minibatch loss at step 0: 0.000067\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 1000: 0.000404\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 2000: 0.000040\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 3000: 0.000154\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000155\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Duration: 121.17%\n",
      "Minibatch loss at step 0: 0.000065\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 1000: 0.000395\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 2000: 0.000040\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 3000: 0.000147\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 4000: 0.000153\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Duration: 121.22%\n",
      "Test accuracy: 98.8%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 60\n",
    "num_steps = 50000/batch_size\n",
    "\n",
    "'''\n",
    "for each epoch\n",
    "   randomly shuffle training data\n",
    "   for each N size batch of training data\n",
    "      train model\n",
    "   view train cost\n",
    "   compute train accuracy\n",
    "   view valid cost\n",
    "   compute valid accuracy\n",
    "compute test accuracy\n",
    "'''\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print \"Initialized\"\n",
    "    best_validation_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            batch_data = train_data[offset:(offset + batch_size), :, :, :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Feed dictionary\n",
    "            feed_dict = {x: batch_data, y: batch_labels}\n",
    "            _, C, pred = session.run([optimizer,loss,predictions],feed_dict=feed_dict)\n",
    "            if (step % 1000 == 0):\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, C))\n",
    "                print(\"Minibatch accuracy: %.2f%%\" % accuracy(pred, batch_labels))\n",
    "                feed_dict = {x: valid_data}\n",
    "                pred = session.run(predictions, feed_dict=feed_dict)\n",
    "                valid_acc = accuracy(np.array(pred), valid_labels)\n",
    "                print(\"Validation accuracy: %.2f%%\" % valid_acc)\n",
    "                if (valid_acc >= best_validation_acc):\n",
    "                    best_validation_acc = valid_acc\n",
    "                    print \"Best Validation accuracy at step\", step, \"and epoch\", epoch\n",
    "        print (\"Duration: %.2f sec\" % (time.time() - start_time))\n",
    "    feed_dict = {x: test_data}\n",
    "    pred = session.run(predictions, feed_dict=feed_dict)\n",
    "    print (\"Test accuracy: %.1f%%\" % accuracy(np.array(pred), test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expanded_pairs = []\n",
    "j = 0\n",
    "for x, y in zip(train_dataset[0], train_dataset[1]):\n",
    "    expanded_pairs.append((x,y))\n",
    "    image = np.reshape(x, (-1, 28))\n",
    "    j += 1\n",
    "    if j % 1000 == 0: print (\"Expanding impage number\", j)\n",
    "    for d, axis, index_position, index in [\n",
    "        (1, 0, \"first\", 0),\n",
    "        (-1, 0, \"first\", 27),\n",
    "        (1, 1, \"last\", 0),\n",
    "        (-1, 1, \"last\", 27)]:\n",
    "        new_img = np.roll(image, d, axis)\n",
    "        if index_position == 'first':\n",
    "            new_img[index, :] = np.zeros(28)\n",
    "        else:\n",
    "            new_img[:, index] = np.zeros(28)\n",
    "        expanded_pairs.append((np.reshape(new_img, 784), y))\n",
    "random.shuffle(expanded_pairs)\n",
    "expanded_training = [list(d) for d in zip(*expanded_pairs)]\n",
    "print \"Saving expanded data. This may take a few minutes.\"\n",
    "f = gzip.open(\"mnist_expanded.pkl.gz\", \"w\")\n",
    "pickle.dump((expanded_training, valid_dataset, test_dataset), f)\n",
    "f.close()\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gzip.open('mnist_expanded.pkl.gz', 'rb') as f:\n",
    "    train_dataset, valid_dataset, test_dataset = pickle.load(f)\n",
    "\n",
    "print \"Training set\", np.array(train_dataset[0]).shape, np.array(train_dataset[1]).shape\n",
    "print \"Validation set\", valid_dataset[0].shape, valid_dataset[1].shape\n",
    "print \"Test set\", test_dataset[0].shape, test_dataset[1].shape    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
